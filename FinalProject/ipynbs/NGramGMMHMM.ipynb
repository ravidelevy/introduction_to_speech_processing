{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LX5NVY6UkfXF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9df10fcd-58aa-40ea-9623-0e4237d211ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Introduction to Speech Processing\n"
          ]
        }
      ],
      "source": [
        "# This mounts your Google Drive to the Colab VM.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# TODO: Enter the foldername in your Drive where you have saved the unzipped\n",
        "# assignment folder, e.g. 'cs231/assignment1'\n",
        "FOLDERNAME = 'Introduction to Speech Processing/'\n",
        "assert FOLDERNAME is not None, \"[!] Enter the folername.\"\n",
        "\n",
        "# Now that we've mounted your Drive, this ensures that\n",
        "# the Python interpreter of the Colab VM can load\n",
        "# python files from within it\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/{}'.format(FOLDERNAME))\n",
        "\n",
        "%cd /content/drive/MyDrive/$FOLDERNAME"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gSmzdafosHou",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e55cc9ee-2ad9-4354-ead1-bc8a5006a9c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.2.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.0\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.0.2-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from jiwer) (8.1.6)\n",
            "Collecting rapidfuzz==2.13.7 (from jiwer)\n",
            "  Downloading rapidfuzz-2.13.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, jiwer\n",
            "Successfully installed jiwer-3.0.2 rapidfuzz-2.13.7\n"
          ]
        }
      ],
      "source": [
        "!pip install hmmlearn\n",
        "!pip install jiwer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVW_K9GIP905"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import heapq\n",
        "import librosa\n",
        "import operator\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from jiwer import wer, cer\n",
        "from hmmlearn import hmm\n",
        "from statistics import mean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LF2xCV6ntVn_"
      },
      "outputs": [],
      "source": [
        "WHITESPACE = \" \"\n",
        "TRAIN = 'train'\n",
        "TEST = 'test'\n",
        "VAL = 'val'\n",
        "\n",
        "train_txt = os.listdir(f'./an4/{TRAIN}/an4/txt')\n",
        "train_wav = [f'{txt.split(\".\")[0]}.wav' for txt in train_txt]\n",
        "val_txt = os.listdir(f'./an4/{VAL}/an4/txt')\n",
        "val_wav = [f'{txt.split(\".\")[0]}.wav' for txt in val_txt]\n",
        "test_txt = os.listdir(f'./an4/{TEST}/an4/txt')\n",
        "test_wav = [f'{txt.split(\".\")[0]}.wav' for txt in test_txt]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTuI52JW6uAw"
      },
      "outputs": [],
      "source": [
        "def preprocess_audio(file, directory):\n",
        "  audio, sr = librosa.load(f'{directory}/{file}', sr=None)\n",
        "  intervals = librosa.effects.split(audio, top_db=5)\n",
        "  if(intervals.shape[0] > 1):\n",
        "    splitted_audio = []\n",
        "    for interval in intervals:\n",
        "      splitted_audio.append(audio[interval[0]:interval[1]])\n",
        "\n",
        "    audio = np.concatenate(splitted_audio)\n",
        "\n",
        "  audio = librosa.to_mono(audio)\n",
        "  return audio, intervals"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdJzHrYJQYBK"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "interval_train = []\n",
        "X_val = []\n",
        "interval_val = []\n",
        "X_test = []\n",
        "interval_test = []\n",
        "\n",
        "y_train = []\n",
        "y_val = []\n",
        "y_test = []\n",
        "\n",
        "for wav in train_wav:\n",
        "  audio, intervals = preprocess_audio(wav, f'./an4/{TRAIN}/an4/wav/')\n",
        "  X_train.append(audio)\n",
        "  interval_train.append(intervals)\n",
        "\n",
        "for txt in train_txt:\n",
        "  with open(f'./an4/{TRAIN}/an4/txt/{txt}') as file:\n",
        "    y_train.append(file.read().split(\" \"))\n",
        "\n",
        "for wav in val_wav:\n",
        "  audio, intervals = preprocess_audio(wav, f'./an4/{VAL}/an4/wav/')\n",
        "  X_val.append(audio)\n",
        "  interval_val.append(intervals)\n",
        "\n",
        "for txt in val_txt:\n",
        "  with open(f'./an4/{VAL}/an4/txt/{txt}') as file:\n",
        "    y_val.append(file.read().split(\" \"))\n",
        "\n",
        "for wav in test_wav:\n",
        "  audio, intervals = preprocess_audio(wav, f'./an4/{TEST}/an4/wav/')\n",
        "  X_test.append(audio)\n",
        "  interval_test.append(intervals)\n",
        "\n",
        "for txt in test_txt:\n",
        "  with open(f'./an4/{TEST}/an4/txt/{txt}') as file:\n",
        "    y_test.append(file.read().split(\" \"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbgnWDkugIA6"
      },
      "outputs": [],
      "source": [
        "class LanguageModel:\n",
        "\n",
        "  def __init__(self, n_gram=1):\n",
        "    self.probabilities = {}\n",
        "    self.n_gram = n_gram\n",
        "    self.instances = []\n",
        "\n",
        "  def calculate_probabilities(self, train_txt, directory):\n",
        "    bag_of_ngrams = []\n",
        "    for file in train_txt:\n",
        "      with open(f'{directory}/{file}') as txt:\n",
        "        tokens = txt.read().split(\" \")\n",
        "        for i in range(len(tokens)):\n",
        "          n_gram = tokens[i:i + self.n_gram]\n",
        "          if len(n_gram) == self.n_gram:\n",
        "            bag_of_ngrams.append(tuple(n_gram))\n",
        "\n",
        "    number_of_ngrams = len(bag_of_ngrams)\n",
        "    for ngram in bag_of_ngrams:\n",
        "        if ngram[:-1] not in self.probabilities.keys():\n",
        "          self.probabilities[ngram[:-1]] = {}\n",
        "\n",
        "        if ngram[-1] not in self.probabilities[ngram[:-1]].keys():\n",
        "          self.probabilities[ngram[:-1]][ngram[-1]] = 1\n",
        "          self.instances.append(ngram)\n",
        "        else:\n",
        "          self.probabilities[ngram[:-1]][ngram[-1]] += 1\n",
        "\n",
        "    for window in self.probabilities.keys():\n",
        "      number_of_instances = sum(self.probabilities[window].values())\n",
        "      for word in self.probabilities[window].keys():\n",
        "        self.probabilities[window][word] =\\\n",
        "          float(self.probabilities[window][word] / number_of_instances)\n",
        "\n",
        "  def get_probability(self, ngram):\n",
        "    return self.probabilities[ngram[:-1]][ngram[-1]]\n",
        "\n",
        "  def get_instances(self):\n",
        "    return self.instances\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhWjrjA11XQE"
      },
      "outputs": [],
      "source": [
        "def get_mfcc_features(audio, sr=16000):\n",
        "  mfccs = librosa.feature.mfcc(y=audio, sr=sr, n_mfcc=13, n_mels=40, n_fft=512,\n",
        "                               hop_length=128, fmin=0, fmax=None, htk=False)\n",
        "  delta_mfccs = librosa.feature.delta(mfccs, mode='nearest')\n",
        "  delta2_mfccs = librosa.feature.delta(mfccs, order=2, mode='nearest')\n",
        "  mfccs_features = np.concatenate((mfccs, delta_mfccs, delta2_mfccs))\n",
        "\n",
        "  return mfccs_features.T"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jQyGp1SEvNYa"
      },
      "outputs": [],
      "source": [
        "class AcousticModel:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.models_dictionary = {}\n",
        "\n",
        "  def train(self, X, y, intervals, n_gram, n_mix, n_iter):\n",
        "    for i in range(len(X)):\n",
        "      text = y[i]\n",
        "      audio_length = X[i].shape[0]\n",
        "      offset = 0\n",
        "      prev_mfccs = None\n",
        "      if len(intervals[i]) >= n_gram:\n",
        "        for j in range(len(text) - n_gram + 1):\n",
        "          interval_index = min(j, len(intervals[i]) - n_gram)\n",
        "          interval = intervals[i][interval_index + n_gram - 1][1] - intervals[i][interval_index][0]\n",
        "          hmm_gmm = None\n",
        "          key = tuple(text[j:j + n_gram])\n",
        "          if key not in self.models_dictionary.keys():\n",
        "            hmm_gmm = hmm.GMMHMM(n_components=3, n_mix=n_mix, n_iter=n_iter, init_params=\"\", params=\"\")\n",
        "          else:\n",
        "            hmm_gmm = self.models_dictionary[key]\n",
        "\n",
        "          start = offset\n",
        "          end = start + interval\n",
        "          offset += (intervals[i][interval_index][1] - intervals[i][interval_index][0])\n",
        "          section = X[i][start:end]\n",
        "          if section.shape[0] == 0:\n",
        "            mfccs = prev_mfccs\n",
        "          else:\n",
        "            mfccs = get_mfcc_features(section)\n",
        "\n",
        "          hmm_gmm.fit(mfccs)\n",
        "          self.models_dictionary[key] = hmm_gmm\n",
        "          prev_mfccs = mfccs\n",
        "\n",
        "    return self.models_dictionary\n",
        "\n",
        "  def get_model(self, n_gram):\n",
        "    return self.models_dictionary[n_gram]\n",
        "\n",
        "  def get_words(self):\n",
        "    return self.models_dictionary.keys()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGDJQ0m2w-rW"
      },
      "outputs": [],
      "source": [
        "def predict(X, intervals, language_model, acoustic_model, window_size):\n",
        "  y_pred = []\n",
        "  for i in range(len(X)):\n",
        "    audio_length = X[i].shape[0]\n",
        "    offset = 0\n",
        "    prev_mfccs = None\n",
        "    sample_scores = {(): 1}\n",
        "    best_text = None\n",
        "    for j in range(max(len(intervals[i]) - window_size + 1, 1)):\n",
        "      interval_index = max(0, min(j, len(intervals[i]) - window_size))\n",
        "      interval = intervals[i][min(len(intervals[i]) - 1, interval_index + window_size - 1)][1] -\\\n",
        "                   intervals[i][interval_index][0]\n",
        "      start = offset\n",
        "      end = start + interval\n",
        "      offset += (intervals[i][interval_index][1] - intervals[i][interval_index][0])\n",
        "      section = X[i][start:end]\n",
        "      if section.shape[0] == 0:\n",
        "        mfccs = prev_mfccs\n",
        "      else:\n",
        "        mfccs = get_mfcc_features(section)\n",
        "\n",
        "      prev_mfccs = mfccs\n",
        "      interval_scores = {}\n",
        "      scores_update = {}\n",
        "      for n_gram in acoustic_model.models_dictionary.keys():\n",
        "        hmm_gmm = acoustic_model.get_model(n_gram)\n",
        "        interval_scores[n_gram] = 1 / abs(hmm_gmm.score(get_mfcc_features(section)))\n",
        "\n",
        "        for sequence in sample_scores.keys():\n",
        "          for n_gram in interval_scores.keys():\n",
        "            scores_update[sequence + (n_gram[-1],)] =\\\n",
        "              sample_scores[sequence] * interval_scores[n_gram] * language_model.get_probability(n_gram)\n",
        "\n",
        "      sample_scores = scores_update\n",
        "      top_keys = heapq.nlargest(5, sample_scores, key=sample_scores.get)\n",
        "      top_values = [sample_scores[key] for key in top_keys]\n",
        "      sample_scores = {top_keys[i]: top_values[i] for i in range(len(top_keys))}\n",
        "      best_text = top_keys[0]\n",
        "\n",
        "    y_pred.append(list(best_text))\n",
        "\n",
        "  return y_pred\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "goGhhk6zdv-C"
      },
      "outputs": [],
      "source": [
        "models = {}\n",
        "for i in range(1, 6):\n",
        "  language_model = LanguageModel(n_gram=i)\n",
        "  language_model.calculate_probabilities(train_txt, f'./an4/{TRAIN}/an4/txt')\n",
        "\n",
        "  acoustic_model = AcousticModel()\n",
        "  acoustic_model.train(X_train, y_train, interval_train, n_gram=i, n_mix=5, n_iter=100)\n",
        "\n",
        "  models[i] = (language_model, acoustic_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eqcPxH09vag1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1890cb93-8e24-4f67-9b99-ac041c6335eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of window: 1, WER: 0.9770933744617956\n",
            "Size of window: 1, CER: 0.871974895888593\n",
            "Size of window: 2, WER: 1.0\n",
            "Size of window: 2, CER: 1.5460651132294168\n",
            "Size of window: 3, WER: 0.9837976351134246\n",
            "Size of window: 3, CER: 0.9816716159861058\n",
            "Size of window: 4, WER: 0.9709070753807596\n",
            "Size of window: 4, CER: 0.97680954313214\n",
            "Size of window: 5, WER: 0.9726614613456719\n",
            "Size of window: 5, CER: 0.9711317780237775\n",
            "Best window size: 4\n"
          ]
        }
      ],
      "source": [
        "best_wer = 1\n",
        "best_window_size = 1\n",
        "for i in range(1, 6):\n",
        "  y_pred = predict(X_val, interval_val, models[i][0], models[i][1], i)\n",
        "\n",
        "  w_error = []\n",
        "  c_error = []\n",
        "  for j in range(len(y_val)):\n",
        "    w_error.append(wer(WHITESPACE.join(y_val[j]), WHITESPACE.join(y_pred[j])))\n",
        "    c_error.append(cer(WHITESPACE.join(y_val[j]), WHITESPACE.join(y_pred[j])))\n",
        "\n",
        "  mean_w_error = mean(w_error)\n",
        "  mean_c_error = mean(c_error)\n",
        "  print(f'Size of window: {i}, WER: {mean_w_error}')\n",
        "  print(f'Size of window: {i}, CER: {mean_c_error}')\n",
        "  if mean_w_error < best_wer:\n",
        "    best_wer = mean_w_error\n",
        "    best_window_size = i\n",
        "\n",
        "print(f'Best window size: {best_window_size}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2SQF0svAGOp0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "add190bd-0c54-42f1-f1fc-f41f928014a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of window: 4, WER: 0.9640862449516295\n",
            "Size of window: 4, CER: 0.9713895867744256\n"
          ]
        }
      ],
      "source": [
        "y_pred = predict(X_test, interval_test, models[best_window_size][0],\n",
        "                 models[best_window_size][1], best_window_size)\n",
        "\n",
        "w_error = []\n",
        "c_error = []\n",
        "for i in range(len(y_test)):\n",
        "  w_error.append(wer(WHITESPACE.join(y_test[i]), WHITESPACE.join(y_pred[i])))\n",
        "  c_error.append(cer(WHITESPACE.join(y_test[i]), WHITESPACE.join(y_pred[i])))\n",
        "\n",
        "mean_w_error = mean(w_error)\n",
        "mean_c_error = mean(c_error)\n",
        "print(f'Size of window: {best_window_size}, WER: {mean_w_error}')\n",
        "print(f'Size of window: {best_window_size}, CER: {mean_c_error}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PzjwfndLGn1G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09cce8a8-08d3-4831-e4d4-67629b045eda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: ['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['GO']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['ONE', 'FIVE', 'TWO', 'ONE', 'THREE']\n",
            "Predicted: ['J']\n",
            "Target: ['FOUR', 'ONE', 'TWO', 'TWO', 'SIX', 'EIGHT', 'FOUR', 'ONE', 'FOUR', 'TWO']\n",
            "Predicted: ['I']\n",
            "Target: ['B', 'I', 'R', 'C', 'H', 'W', 'O', 'O', 'D']\n",
            "Predicted: ['N', 'N']\n",
            "Target: ['C', 'E', 'D', 'A', 'R', 'V', 'I', 'L', 'L', 'E']\n",
            "Predicted: ['I', 'I', 'I']\n",
            "Target: ['M', 'Y', 'E', 'R', 'S']\n",
            "Predicted: ['I']\n",
            "Target: ['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
            "Predicted: ['N']\n",
            "Target: ['ERASE', 'A', 'B', 'F', 'N', 'Q', 'FIFTY', 'SEVEN']\n",
            "Predicted: ['N', 'M', 'SIXTY']\n",
            "Target: ['TWELVE', 'THIRTY', 'THREE']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['W', 'O', 'O', 'D']\n",
            "Predicted: ['J']\n",
            "Target: ['ENTER', 'TWO', 'NINE', 'EIGHT', 'ONE']\n",
            "Predicted: ['SIXTY', 'J']\n",
            "Target: ['M', 'O', 'R', 'E', 'W', 'O', 'O', 'D']\n",
            "Predicted: ['N', 'N', 'N', 'N']\n",
            "Target: ['J', 'A', 'N', 'E', 'T']\n",
            "Predicted: ['I']\n",
            "Target: ['L', 'E', 'V', 'I', 'S', 'O', 'N']\n",
            "Predicted: ['I']\n",
            "Target: ['THREE', 'ZERO', 'TWO', 'ONE']\n",
            "Predicted: ['I']\n",
            "Target: ['ENTER', 'TWO', 'EIGHTEEN']\n",
            "Predicted: ['K']\n",
            "Target: ['ERASE', 'E', 'D', 'Z', 'E', 'FIFTY', 'SIX']\n",
            "Predicted: ['W']\n",
            "Target: ['J', 'P', 'E', 'G', 'FOUR']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['ONE', 'THREE', 'SEVEN']\n",
            "Predicted: ['I']\n",
            "Target: ['OCTOBER', 'TWENTY', 'FOUR', 'NINETEEN', 'SEVENTY']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['RUBOUT', 'G', 'M', 'E', 'F', 'THREE', 'NINE']\n",
            "Predicted: ['J', 'J']\n",
            "Target: ['ENTER', 'EIGHT', 'THIRTEEN']\n",
            "Predicted: ['ONE']\n",
            "Target: ['NO']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['ENTER', 'SEVEN', 'ONE', 'FIVE', 'FOUR']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['P', 'H', 'I', 'N', 'N', 'E', 'Y']\n",
            "Predicted: ['N']\n",
            "Target: ['ONE', 'FIVE', 'TWO', 'TWO', 'SEVEN']\n",
            "Predicted: ['J']\n",
            "Target: ['THREE', 'THREE', 'ONE', 'OH', 'ONE', 'EIGHT', 'EIGHT']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['OH', 'TWO', 'ONE', 'SEVEN', 'THREE']\n",
            "Predicted: ['J']\n",
            "Target: ['ONE', 'FOUR', 'SIX', 'ONE', 'EIGHT']\n",
            "Predicted: ['I']\n",
            "Target: ['TWO', 'TWO', 'SIX']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['ERASE', 'K', 'M', 'H', 'N', 'I', 'SIX', 'OH', 'FIVE']\n",
            "Predicted: ['N']\n",
            "Target: ['RUBOUT', 'N', 'I', 'M', 'N', 'ONE']\n",
            "Predicted: ['V', 'V']\n",
            "Target: ['MAY', 'SECOND', 'NINETEEN', 'SIXTY', 'FIVE']\n",
            "Predicted: ['M']\n",
            "Target: ['STOP']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['W', 'I', 'L', 'L', 'E', 'T', 'T']\n",
            "Predicted: ['V']\n",
            "Target: ['SIX', 'EIGHT', 'THREE', 'SIX', 'ZERO', 'TWO', 'SEVEN']\n",
            "Predicted: ['SIXTY', 'SIXTY', 'SIXTY']\n",
            "Target: ['RUBOUT', 'U', 'B', 'U', 'T', 'R', 'SIX']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['ONE', 'FIVE', 'TWO', 'ONE', 'SEVEN']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['R', 'O', 'C', 'H', 'E', 'S', 'T', 'E', 'R']\n",
            "Predicted: ['I']\n",
            "Target: ['ERASE', 'U', 'D', 'B', 'E', 'FIVE']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['M', 'E', 'L', 'V', 'I', 'N']\n",
            "Predicted: ['I', 'N', 'V']\n",
            "Target: ['NO']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['ENTER', 'ONE', 'SEVENTY', 'SIX']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['SIXTY', 'SIX', 'THIRTY', 'THREE']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['X', 'K', 'I', 'T', 'B', 'TWO', 'SIX', 'ONE', 'ONE']\n",
            "Predicted: ['M']\n",
            "Target: ['X', 'N', 'K', 'U', 'EIGHT']\n",
            "Predicted: ['K']\n",
            "Target: ['ENTER', 'SEVEN']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['ELEVEN', 'TWENTY', 'SEVEN', 'FIFTY', 'SEVEN']\n",
            "Predicted: ['ONE']\n",
            "Target: ['I', 'V', 'A', 'N']\n",
            "Predicted: ['N']\n",
            "Target: ['P', 'O', 'W', 'E', 'L', 'L']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['B', 'A', 'O', 'Z', 'FIVE', 'THREE']\n",
            "Predicted: ['N']\n",
            "Target: ['M', 'A', 'R', 'G', 'A', 'R', 'E', 'T', 'M', 'O', 'R', 'R', 'I', 'S', 'O', 'N']\n",
            "Predicted: ['N', 'N', 'N', 'N', 'N']\n",
            "Target: ['L', 'E', 'X', 'I', 'N', 'G', 'T', 'O', 'N']\n",
            "Predicted: ['M']\n",
            "Target: ['M', 'C', 'K', 'E', 'E', 'S', 'R', 'O', 'C', 'K', 'S']\n",
            "Predicted: ['N', 'N', 'N', 'N']\n",
            "Target: ['RUBOUT', 'N', 'S', 'V', 'H', 'T', 'SIX', 'FORTY', 'NINE']\n",
            "Predicted: ['M']\n",
            "Target: ['J', 'E', 'F', 'F', 'R', 'E', 'Y']\n",
            "Predicted: ['P']\n",
            "Target: ['YES']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['ENTER', 'ONE', 'OH', 'FOUR']\n",
            "Predicted: ['J', 'I']\n",
            "Target: ['C', 'E', 'N', 'T', 'R', 'E']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['EIGHT', 'EIGHT', 'FOUR', 'THREE', 'SIX', 'FOUR', 'EIGHT']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['A', 'B', 'V', 'J', 'NINETY', 'FOUR']\n",
            "Predicted: ['K']\n",
            "Target: ['ONE', 'FIVE', 'TWO', 'TWO', 'FOUR']\n",
            "Predicted: ['I']\n",
            "Target: ['ONE', 'FIVE', 'ONE', 'THREE', 'SIX']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['P', 'L', 'E', 'A', 'S', 'A', 'N', 'T', 'H', 'I', 'L', 'L', 'S']\n",
            "Predicted: ['I', 'I', 'I', 'I', 'I', 'I', 'V', 'V', 'V']\n",
            "Target: ['ERASE', 'X', 'A', 'G', 'N', 'A', 'SIX', 'THIRTY', 'FIVE']\n",
            "Predicted: ['FIVE', 'FIVE', 'FIVE', 'FIVE', 'FIVE', 'SEVEN']\n",
            "Target: ['JUNE', 'EIGHTEENTH', 'NINETEEN', 'SIXTY', 'EIGHT']\n",
            "Predicted: ['ONE']\n",
            "Target: ['SIX', 'EIGHT', 'THREE', 'THREE', 'OH', 'SEVEN', 'FIVE']\n",
            "Predicted: ['EIGHT', 'EIGHT']\n",
            "Target: ['S', 'A', 'N', 'D', 'L', 'E', 'R']\n",
            "Predicted: ['NINETEEN', 'M']\n",
            "Target: ['S', 'Y', 'F', 'C', 'D', 'NINE', 'SIX', 'OH', 'ONE', 'SEVEN']\n",
            "Predicted: ['FIVE', 'N', 'N', 'N']\n",
            "Target: ['ONE', 'FIVE', 'TWO', 'THREE', 'SIX']\n",
            "Predicted: ['I']\n",
            "Target: ['ENTER', 'TWENTY', 'ONE']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['A', 'L', 'A', 'N']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['ENTER', 'FIVE', 'SIX', 'EIGHT']\n",
            "Predicted: ['I']\n",
            "Target: ['G', 'I', 'N', 'S', 'B', 'E', 'R', 'G']\n",
            "Predicted: ['FIFTEEN', 'I']\n",
            "Target: ['FIFTY', 'TWO', 'NINETEEN']\n",
            "Predicted: ['FIFTY']\n",
            "Target: ['NOVEMBER', 'NINTH', 'SIXTY', 'FIVE']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['ONE', 'FIFTY']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['TWO', 'SIX', 'EIGHT', 'FOUR', 'SIX', 'NINE', 'FOUR']\n",
            "Predicted: ['SIXTY', 'ZERO', 'ZERO', 'ZERO']\n",
            "Target: ['R', 'H', 'N', 'G', 'A', 'FIFTY', 'FOUR', 'EIGHTY', 'THREE']\n",
            "Predicted: ['N']\n",
            "Target: ['ENTER', 'THIRTY']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['W', 'Y', 'A', 'T', 'U', 'SEVENTY', 'SEVEN', 'SEVENTY', 'SEVEN']\n",
            "Predicted: ['J']\n",
            "Target: ['FOUR', 'TWO', 'ONE', 'EIGHT', 'EIGHT', 'SIX', 'OH']\n",
            "Predicted: ['I', 'N']\n",
            "Target: ['ENTER', 'NINE', 'ONE', 'SIX', 'NINE']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['NO']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['TWO', 'FORTY']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['MARCH', 'SEVEN', 'NINETEEN', 'SIXTY', 'SEVEN']\n",
            "Predicted: ['NINETEEN']\n",
            "Target: ['RUBOUT', 'V', 'Z', 'J', 'H', 'P', 'SEVEN', 'THIRTY', 'SIX']\n",
            "Predicted: ['M']\n",
            "Target: ['M', 'I', 'C', 'H', 'A', 'E', 'L']\n",
            "Predicted: ['M', 'N']\n",
            "Target: ['W', 'I', 'L', 'L', 'O', 'W', 'B', 'E', 'N', 'D']\n",
            "Predicted: ['P', 'P']\n",
            "Target: ['A', 'SEVEN']\n",
            "Predicted: ['K']\n",
            "Target: ['V', 'A', 'N', 'E', 'S', 'S', 'A']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['K', 'A', 'U', 'F', 'M', 'A', 'N']\n",
            "Predicted: ['K']\n",
            "Target: ['D', 'A', 'V', 'I', 'D']\n",
            "Predicted: ['K', 'Z']\n",
            "Target: ['H', 'O', 'U', 'S', 'E', 'R']\n",
            "Predicted: ['FIVE', 'FIVE']\n",
            "Target: ['ERASE', 'F', 'O', 'X', 'K', 'EIGHT']\n",
            "Predicted: ['M']\n",
            "Target: ['D', 'A', 'J', 'N', 'H', 'NINETY', 'SIX']\n",
            "Predicted: ['U', 'U']\n",
            "Target: ['Y', 'A', 'N', 'A', 'S', 'A', 'K']\n",
            "Predicted: ['N']\n",
            "Target: ['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
            "Predicted: ['FIVE', 'I']\n",
            "Target: ['E', 'R', 'I', 'C']\n",
            "Predicted: ['N']\n",
            "Target: ['T', 'R', 'T', 'F', 'I', 'SEVEN']\n",
            "Predicted: ['ZERO', 'ZERO', 'N']\n",
            "Target: ['RUBOUT', 'C', 'B', 'W', 'X', 'V', 'FOUR']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['RUBOUT', 'E', 'Y', 'F', 'C', 'X', 'FOUR']\n",
            "Predicted: ['ONE']\n",
            "Target: ['G', 'F', 'T', 'U', 'ONE', 'THREE', 'THREE', 'TWO']\n",
            "Predicted: ['M', 'M']\n",
            "Target: ['L', 'K', 'K', 'N', 'THIRTY', 'EIGHT']\n",
            "Predicted: ['M', 'K']\n",
            "Target: ['TWELVE', 'TWENTY', 'NINE', 'FIFTY', 'NINE']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['SIX', 'FIVE', 'FIVE', 'EIGHT', 'SEVEN', 'FOUR', 'ZERO']\n",
            "Predicted: ['I', 'V', 'N']\n",
            "Target: ['NINETEEN']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['S', 'P', 'E', 'E', 'R']\n",
            "Predicted: ['I', 'P']\n",
            "Target: ['ENTER', 'FOUR', 'FIVE', 'EIGHT', 'TWO', 'ONE']\n",
            "Predicted: ['ZERO']\n",
            "Target: ['ERASE', 'P', 'Q', 'Y', 'V', 'T', 'FIVE', 'NINETY', 'EIGHT']\n",
            "Predicted: ['FIVE']\n",
            "Target: ['ENTER', 'EIGHT']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['ENTER', 'NINE', 'TWO', 'EIGHT']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['JANUARY', 'SEVENTH', 'NINETEEN', 'SIXTY', 'SEVEN']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['ONE', 'FIVE', 'TWO', 'ONE', 'THREE']\n",
            "Predicted: ['M']\n",
            "Target: ['B', 'R', 'E', 'N', 'T', 'W', 'O', 'O', 'D']\n",
            "Predicted: ['N']\n",
            "Target: ['FIVE', 'TWENTY', 'SEVEN', 'SIXTY', 'SIX']\n",
            "Predicted: ['W']\n",
            "Target: ['ERASE', 'C', 'Q', 'Q', 'F', 'SEVEN']\n",
            "Predicted: ['I']\n",
            "Target: ['C', 'I', 'N', 'D', 'Y']\n",
            "Predicted: ['I']\n",
            "Target: ['TEN', 'TWENTY', 'SEVEN', 'SIXTY', 'TWO']\n",
            "Predicted: ['J']\n",
            "Target: ['P', 'A', 'T', 'T', 'E', 'R', 'S', 'O', 'N']\n",
            "Predicted: ['P', 'N', 'I', 'I']\n",
            "Target: ['ENTER', 'EIGHT', 'NINETY', 'SEVEN']\n",
            "Predicted: ['U']\n",
            "Target: ['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
            "Predicted: ['N', 'N']\n",
            "Target: ['ONE', 'FIVE', 'TWO', 'THREE', 'TWO']\n",
            "Predicted: ['J', 'M']\n",
            "Target: ['REPEAT']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['P', 'I', 'T', 'T', 'S', 'B', 'U', 'R', 'G', 'H']\n",
            "Predicted: ['I', 'I', 'I']\n",
            "Target: ['EIGHT', 'SIX', 'TWO', 'OH', 'THREE', 'EIGHT', 'SEVEN']\n",
            "Predicted: ['W']\n",
            "Target: ['RUBOUT', 'G', 'R', 'A', 'G', 'EIGHTY', 'FIVE']\n",
            "Predicted: ['SIXTY']\n",
            "Target: ['SEVEN', 'ONE', 'SIX', 'TWO', 'FOUR', 'FOUR', 'SIX', 'SEVEN', 'ONE', 'FOUR']\n",
            "Predicted: ['NINETEEN', 'NINETEEN']\n",
            "Target: ['J', 'O', 'H', 'N']\n",
            "Predicted: ['EIGHT']\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(y_test)):\n",
        "  print(f'Target: {y_test[i]}')\n",
        "  print(f'Predicted: {y_pred[i]}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}