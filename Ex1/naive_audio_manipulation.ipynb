{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "id": "8nr0aixa8N3r"
      },
      "source": [
        "In this part of the exercise we will be experimenting with modifying audio in various ways to stretch / shrink it through time and to modify it's pitch.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import soundfile as sf\n",
        "import librosa.feature\n",
        "import numpy as np\n",
        "import scipy as sc\n",
        "import torchaudio\n",
        "import librosa\n",
        "import torch\n",
        "import math"
      ],
      "metadata": {
        "id": "D5TeGSYGMQb6"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "42JwukDZ8N3t"
      },
      "source": [
        "Part A: Interpolating over time.\n",
        "\n",
        "1. load 'audio_16k/Basta_16k.wav' audio file (note that it is on stereo)\n",
        "2. use `torch.nn.functional.interpolate` with `mode='bilinear` to stretch / compress the signal with 1.2, 0.8 factor respectfully.\n",
        "3. save these samples to outputs directory as 'interpolation_0_8.wav', 'interpolation_1_2.wav' and listen to them, do you notice something odd? why do you think this happens? - answear in a markdown cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "3YcPxixG8N3t"
      },
      "outputs": [],
      "source": [
        "# Place your code for this part here\n",
        "filepath = 'audio_16k/Basta_16k.wav'\n",
        "data, samplerate = sf.read(filepath)\n",
        "\n",
        "input = torch.unsqueeze(torch.unsqueeze(torch.tensor(data), dim=0), dim=0)\n",
        "interpolation_compressed = torch.nn.functional.interpolate(input, scale_factor=0.8, mode='bilinear')\n",
        "interpolation_stretched = torch.nn.functional.interpolate(input, scale_factor=1.2, mode='bilinear')\n",
        "\n",
        "compressed_filepath = 'outputs/interpolation_0_8.wav'\n",
        "compressed_squeezed = torch.squeeze(interpolation_compressed, dim=0)[0]\n",
        "sf.write(compressed_filepath, compressed_squeezed.numpy(), samplerate)\n",
        "\n",
        "stretched_filepath = 'outputs/interpolation_1_2.wav'\n",
        "stretched_squeezed = torch.squeeze(torch.squeeze(interpolation_stretched, dim=0))\n",
        "sf.write(stretched_filepath, stretched_squeezed.numpy(), samplerate)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "G_kUA1HH8N3t"
      },
      "source": [
        "Answer non-code questions here\n",
        "\n",
        "3. The odd thing we observed while playing the new audio files, is that the original audio was preserved in both cases, but its pitch became slower and lower/faster and higher, in the streched/compressed versions respectfully. \\\\\n",
        "We think it is caused from the interpolation, which stretched/compressed the audio waves, and as a result the frequency became lower/higher on the one hand, and on the other hand it is preserved the original data, it made the wave lengths longer/shorter accordingly."
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "3P89jpT38N3u"
      },
      "source": [
        "Part B: Naive time stretch (tempo shift).\n",
        "\n",
        "In this part you would be required to write two NAIVE functions that perform a SIMPLE augmentation over the audio:\n",
        "1. `naive_tempo_shift(wav, factor)` = stretch an audiofile by a given factor, e.g 0.8 factor should result a slowdown to 0.8x the original audio (output a LONGER wav). \n",
        "2. load 'audio_16k/Basta_16k.wav' and generate a tempo shift of x{0.8, 1.2} and save these generated audio files to outputs/naive_pitch_shift_{factor using _ instead if .}.wav\n",
        "\n",
        "Note: This should be a Naive implementation, achieveable using torch.stft, torch.istft, torch.fft.fft, torch.fft.ifft alone and programable in a few lines per function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "15SJbrW08N3u"
      },
      "outputs": [],
      "source": [
        "# Place your code for this part here\n",
        "def naive_tempo_shift(wav, factor):\n",
        "  data, samplerate = sf.read(wav)\n",
        "\n",
        "  freq_domain = torch.stft(torch.tensor(data.T), n_fft=1024, win_length=1024,\n",
        "                           hop_length=int(256*factor), return_complex=True)\n",
        "  return torch.istft(freq_domain, n_fft=1024, win_length=1024,\n",
        "                     hop_length=256).T, samplerate\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output, samplerate = naive_tempo_shift('audio_16k/Basta_16k.wav', 0.8)\n",
        "sf.write('outputs/naive_pitch_shift_0_8.wav', output, samplerate)\n",
        "\n",
        "output, samplerate = naive_tempo_shift('audio_16k/Basta_16k.wav', 1.2)\n",
        "sf.write('outputs/naive_pitch_shift_1_2.wav', output, samplerate)"
      ],
      "metadata": {
        "id": "EJDjKS1L6Sw-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "H8v9K1DB8N3u"
      },
      "source": [
        "Part C: Phase vocoder \\\\\n",
        "In this subsection you will implement version of a slightly better algorithm to perform time_stretch called Phase vocoder.\n",
        "We do not aim to get into depth of this algorithm design, yet we think that this algorithm is cool to know so in this part you will implement it from a given pseudo code.\n",
        "\n",
        "1. Implement the algorithm following the pseudo code below for the function time_stretch.\n",
        "2. Load 'audio_16k/Basta_16k.wav' and use time_stretch with factors x0.8, 1.2, save these generations to `outputs/phase_vocoder_{factor, replace '.' with '_'}.wav`\n",
        "3. Do you notice anything different from the previous naive time stretch (besides magnitude differences)? why do you think it is different?\n",
        "\n",
        "Guidance: use torch, torchaudio functions in this section. \n",
        "\n",
        "-\n",
        "Pseudo code:\n",
        "-\n",
        "\n",
        "time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
        "    # create window\n",
        "    hann_window = construct_hann_window(win_size)\n",
        "\n",
        "    # draw two complex STFTs\n",
        "    new_hop = int(hop * factor)\n",
        "    stft_left = get_complex_stft(signal[:-hop], win_size, new_hop, hann_window)\n",
        "    stft_right = get_complex_stft(signal[hop:], win_size, new_hop, hann_window)\n",
        "\n",
        "    # calculate accumulated phase delta with modulus (2 pi)\n",
        "    phase = get_acc_phase_delta(stft_left, stft_right)\n",
        "\n",
        "    # reconstruct component from phase\n",
        "    re, im = get_re_im_from_phase(phase)\n",
        "    complex_new_stft = view_as_complex(stack([re, im], dim=-1)) * abs(stft_right))\n",
        "    output = istft(complex_new_stft, win_length=win_size, hop_length=hop, window=hann_window)\n",
        "\n",
        "    return output\n",
        "\n",
        "-\n",
        "Pseudo functions:\n",
        "-\n",
        "\n",
        "construct_hann_window(win_size):\n",
        "    return a vector representing a hanning window, hint: see torch.hann_window\n",
        "\n",
        "get_complex_stft(signal, win_size, hop, window):\n",
        "    return a complex representation of the stft (x + jy form)\n",
        "\n",
        "get_acc_phase_delta(stft_left, stft_right):\n",
        "    # calculate angular distance between two complex STFTs\n",
        "    phase_delta = angle(stft_right) - angle(stft_left)\n",
        "\n",
        "    # accumulate phase, follow this recursive formula\n",
        "    for i in {1...length(phase_delta)}: phase[i] := phase_delta[i] + phase[i-1]; phase[0] = phase_delta[0]\n",
        "    \n",
        "    # round phase back to 0 - 2 * pi range\n",
        "    phase = phase % (2 * pi * round(phase_delta / (2 * pi)))  \n",
        "\n",
        "    return phase\n",
        "\n",
        "get_re_im_from_phase(phase):\n",
        "    retrieves the real and imaginary components from a complex phase"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_acc_phase_delta(stft_left, stft_right):\n",
        "  # calculate angular distance between two complex STFTs\n",
        "  phase_delta = torch.angle(stft_right) - torch.angle(stft_left)\n",
        "  phase = torch.Tensor(np.zeros(phase_delta.shape))\n",
        "\n",
        "  # accumulate phase, follow this recursive formula\n",
        "  phase[:, :, 0] = phase_delta[:, :, 0]\n",
        "  for i in range(1, phase.numpy().shape[2]):\n",
        "    phase[:, :, i] = phase_delta[:, :, i] + phase[:, :, i-1]\n",
        "  \n",
        "  # round phase back to 0 - 2 * pi range\n",
        "  phase = phase - 2 * np.pi * torch.round(phase / (2 * np.pi))\n",
        "\n",
        "  return phase"
      ],
      "metadata": {
        "id": "IqZdv64WePU3"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def time_stretch(signal, factor, win_size=1024, hop=1024//4):\n",
        "  # create window\n",
        "  hann_window = torch.hann_window(win_size)\n",
        "\n",
        "  # draw two complex STFTs\n",
        "  new_hop = int(hop * factor)\n",
        "  stft_left = torch.stft(torch.tensor(signal[:-hop].T), n_fft=win_size, win_length=win_size,\n",
        "                         hop_length=new_hop, window=hann_window, return_complex=True)\n",
        "  stft_right = torch.stft(torch.tensor(signal[hop:].T), n_fft=win_size, win_length=win_size,\n",
        "                         hop_length=new_hop, window=hann_window, return_complex=True)\n",
        "\n",
        "  # calculate accumulated phase delta with modulus (2 pi)\n",
        "  phase = get_acc_phase_delta(stft_left, stft_right)\n",
        "\n",
        "  # reconstruct component from phase\n",
        "  get_re_im_from_phase = lambda phase: (torch.cos(phase), torch.sin(phase))\n",
        "  re, im = get_re_im_from_phase(phase)\n",
        "  complex_new_stft = torch.complex(re, im) * abs(stft_right)\n",
        "  output = torch.istft(complex_new_stft, n_fft=win_size, win_length=win_size,\n",
        "                       hop_length=hop, window=hann_window).T\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "mF4kKJGbZmeE"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "0TxlMkfZ8N3u"
      },
      "outputs": [],
      "source": [
        "# Place your code for this part here\n",
        "data, samplerate = sf.read('audio_16k/Basta_16k.wav')\n",
        "output = time_stretch(data, 0.8)\n",
        "sf.write('outputs/phase_vocoder_0_8.wav', output, samplerate)\n",
        "\n",
        "data, samplerate = sf.read('audio_16k/Basta_16k.wav')\n",
        "output = time_stretch(data, 1.2)\n",
        "sf.write('outputs/phase_vocoder_1_2.wav', output, samplerate)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "mH7bWGUK8N3u"
      },
      "source": [
        "Answer non-code questions here \\\\\n",
        "3. The current time stretch is with much less noise compared to the previous naive one. We believe it is because of the hanning windows, which made the stft outputs more coherent around the center of the windows, therefore making diffenece of the stft outputs angles less noisy for the istft operation. Finally, the recovered signal was resulted with much less noise, thanks to that."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}